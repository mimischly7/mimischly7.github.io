Paper "Reliable Text-to-SQL with Adaptive Abstention" by Nick Koudas.

Dear Mr Koudas,
 


Hi Mimi

Thank you for your interest. Let me know what questions you have and I will be happy to elaborate. The project is new
and the first research papers are just coming out lots remain to be done! Happy to chat if you are interested.

thanks
Nick




Dear Dr Koudas,

This is exciting to hear!

I was reading your paper "Reliable Text-to-SQL with Adaptive Abstention" and found your approach to assessing the schema-linking model's uncertainty (especially given the inherent overconfidence of fine-tuned llms) very compelling. I think the ability to provide statistical guarantees throughout the models' generative process is of paramount importance in settings where guesswork is not permissible. And the fact that RTS can easily be employed in any existing text-to-sql framework (assuming of course a transparent llm for schema linking, giving us access to all intermediary hidden states), makes it very attractive.

---- 

As I am not yet a seasoned paper reader, I would like to ask you some questions to make sure I understand things correctly.

Firstly, in the schema linking task, say we have a query and we know the ground truth tokens (which, when concatenated, form the ground truth tables and columns). When building our training corpus, to detect a branching token, we compare every token generated by our model (in order) with the corresponding ground truth token, and the first token that is different from its equivalent ground truth token is eligible for being considered a branching point. My question is, why is it ok to just consider a specific token ordering in the ground truth tokens?
For example, say the prompt is "names of ontario citizens that are members of a band". And let's say the ground truth relations are `Citizen` and `BandMembership` with columns [Province] and [Member] respectively. If the ground truth tokens (just for relations for brevity) are concatenated to `Citizen,BandMembership` and our model generates tokens that concatenate to the same two relations but with the names reversed (e.g. `Membership,Citizen`), won't we erroneously flag a branching point, making the FAR metric worse? Couldn't it be beneficial to first generate a set of all valid token orderings that correspond to the same relations (as the ground truth relations), and check each one of those each time our model generates a token?

Secondly, I had more of a theoretical question for training the u_i classifiers that, given a hidden state of a token (in a particular layer), output a softmax-squashed value for whether the token is a branching point or not. In the paper we train a separate classifier for each hidden layer of the LLM (the llm for schema linking) and then "combine" the results using the provided conformal prediction setup to come up with a final decision of whether the token is a branching point. What are the advantages/disadvantages of this approach as opposed to using a single MLP (or perhaps different architecture with the number of parameters not growing as fast with the input dimension) that takes as input all of the hidden layer encodings (for a given token, as before) at once? Do you think that the larger "all-inclusive" MLP may be more able to take advantage of the relationship between hidden states and identify when a "regression" has happened more effectively? And I believe a similar conformal prediction setup could be employed here to also achieve statistical guarantees? Of course the larger classifier would be harder to train (both in terms of computational resources and possibly in terms of amount of training data required to have the learning converge).

Thirdly, if I did not misunderstand, the FAR (false abstention rate) and TAR (true abstestion rates) formulas appear to be interchanged in the text?

---

Zooming out again, I am very interested in the work you are doing for REDD. From my experience, a lot of SaS providers are trying to integrate RAG into their products, and in the company where I interned last summer there were a lot of customers requesting that we provide such a service -- something we were only doing internally at the time. But I believe that the analytical (yet reliable) querying ability that REDD aims to provide (as opposed to just querying the closest matching chunk or document in traditional rag), especially as a near "plug-and-play" tool that companies can use over their unstructured data, is the next step, and is something that will be highly sought after.

I would love to arrange a meeting with you, at your convenience, and discuss the possibility of contributing to your work.

Thank you for considering my questions.

Sincerely,

Mimis Chlympatsos